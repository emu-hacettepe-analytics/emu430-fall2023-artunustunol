```{r}
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
library(dplyr)
library(ggplot2)
library(rvest)
library(gridExtra)
Sys.setlocale("LC_ALL", "en_US.UTF-8")

# vectors that contains URL's
urls <- c("https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-03-11&num_votes=2500,&country_of_origin=TR&count=250" , 
          "https://m.imdb.com/search/title/?title_type=feature&release_date=,2010-01-01&num_votes=2500,&country_of_origin=TR&count=250")

# read html and save it to a list 
page <- lapply(urls, function(url) {
  read_html(url)
})



# Get the title data
titles_list <- lapply(urls, function(url) {
  page <- read_html(url, encoding = "UTF-8")
  titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
  titles <- html_text(titles_nodes)
  return(titles)
})

# combine titles on a new variable
all_titles <- unlist(titles_list)

# clean the data from the words "Advanced" and "Recently"
all_titles <- all_titles[!grepl("Advanced", all_titles)]
all_titles <- all_titles[!grepl("Recently", all_titles)]

all_titles_cleaned <- c()
for (x in all_titles) {
  a <- gsub("^[0-9]+\\.\\s*", "", x)
  all_titles_cleaned <- c(all_titles_cleaned, a)
}


years_list <- lapply(urls, function(url) {
  page <- read_html(url, encoding = "UTF-8")  # I tried to use UTF-8 to solve the problem for Turkish characters but I couldn't
  years_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')
  years <- html_text(years_nodes)
  return(years)
})

# Combine year data
all_years <- unlist(years_list)

years_cleaned <- c()
for (a in all_years) {
  x <- grep("^[0-9]+$", a, value = TRUE)
  years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- as.integer(years_cleaned)

durations_list <- lapply(urls, function(url) {
  page <- read_html(url, encoding = "UTF-8")  
  durations_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')
  durations <- html_text(durations_nodes)
  return(durations)
})

durations_cleaned <- c()
for (a in durations_list) {
  x <- grep("[hm]", a, value = TRUE)
  durations_cleaned <- c(durations_cleaned, x)
}

convert_to_minutes <- function(durations_cleaned) {

    hours <- as.numeric(str_extract(durations_cleaned, "\\d+(?=h)"))
    minutes <- as.numeric(str_extract(durations_cleaned, "\\d+(?=m)"))
    
    if (is.na(hours)) { hours <- 0 }
    if (is.na(minutes)) { minutes <- 0 }
    
    total_minutes <- hours * 60 + minutes
    return(total_minutes)
}
durations_converted <- c()
for (a in durations_cleaned){
  x <- convert_to_minutes(a)
  durations_converted <- c(durations_converted, x)
}

ratings_list <- lapply(urls, function(url) {
  page <- read_html(url, encoding = "UTF-8") 
  ratings_nodes <- html_nodes(page, '.ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating')
  ratings <- html_text(ratings_nodes)
  return(ratings)
})

all_ratings <- unlist(ratings_list)

ratings_cleaned <- c()
for (x in all_ratings) {
  rating_elements <- sub("^([0-9]\\.[0-9]).*$", "\\1", x)
  ratings_cleaned <- c(ratings_cleaned, rating_elements)
}

ratings_cleaned_integer <- as.numeric(ratings_cleaned)

votes_list <- lapply(urls, function(url) {
  page <- read_html(url, encoding = "UTF-8")  
  votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  
  votes <- html_text(votes_nodes)
  return(votes)
})

all_votes <- unlist(votes_list)

votes_cleaned <- as.numeric(sapply(all_votes, function(x) {
  numeric_value <- gsub("Votes|,", "", x)
}))

final_data <- data.frame(Title = all_titles_cleaned,
                         Year = years_cleaned,
                         Duration = durations_converted,
                         Rating = ratings_cleaned_integer,
                         Vote = votes_cleaned)

final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE),]
best_five <- head(final_data_rated)
worst_five <- tail(final_data_rated)
#To be honest, I didn't watch top five movies except Fundamentals, I'm a huge fan of Cem Yılmaz.
# And of course I didn't punish myself with Cumali Ceber or any other movies of worst five

cem_yilmaz_classics <- filter(final_data, Title %in% c("G.O.R.A.","Av Mevsimi"))

yearly_avg_ratings <- final_data %>%
  group_by(Year) %>%
  summarise(Average_Rating = mean(Rating, na.rm = TRUE))

# Scatter plot oluşturma
plot_scatter <- ggplot(yearly_avg_ratings, aes(x = Year, y = Average_Rating)) +
  geom_point() +
  theme_minimal() +
  labs(title = "Yearly Rating Averages ", x = "Year", y = "Average Rating")

plot_box <- ggplot(final_data, aes(x = as.factor(Year), y = Rating)) +
  geom_boxplot() +
  theme_minimal() +
  labs(title = "Yearly Rating Averages", x = "Year", y = "Average Rating") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

grid.arrange(plot_box, plot_scatter, ncol = 2)

#With the box plot, we can see that the variation of ratings increase over time. The reason of this might be increased number of movies produced in years, in addition to that; accessibility of movie making is higher and this leads to a high number of poorly-produced or amateurly-produced movies.

ggplot(final_data, aes( Vote, Rating)) +
  geom_point(alpha = 0.5)+
  geom_smooth(method = "lm", color = "red")+
  scale_x_log10() +
  theme_minimal()+
  labs(title = "Correlation Between Ratings and Vote")

ggplot(final_data, aes( Duration, Rating)) +
  geom_point(alpha = 0.5)+
  geom_smooth(method = "lm", color = "yellow")+
  scale_x_log10() +
  theme_minimal()+
  labs(title = "Correlation Between Ratings and Durations")

cor_vote_duration <- cor.test(final_data$Vote, final_data$Duration, 
                    method = "pearson")

cor_vote_ratings <- cor.test(final_data$Vote, final_data$Rating, 
                    method = "pearson")

#These correlation tests emphasises that duration and vote are more correlated than ratings and vote.

url_top1000 <- "https://m.imdb.com/search/title/?title_type=feature&groups=top_1000&country_of_origin=TR"
#data_top1000 <- read_html(url_top1000)

titles_top1000 <- lapply(urls, function(url) {
  page <- read_html(url_top1000, encoding = "UTF-8")
  titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
  titles <- html_text(titles_nodes)
  return(titles)
})


titles_top1000_cleaned <- c()
for (x in titles_top1000) {
  a <- gsub("^[0-9]+\\.\\s*", "", x)
  titles_top1000_cleaned <- c(titles_top1000_cleaned, a)
}

titles_top1000_cleaned <- titles_top1000_cleaned[!grepl("Advanced", titles_top1000_cleaned)]
titles_top1000_cleaned <- titles_top1000_cleaned[!grepl("Recently", titles_top1000_cleaned)]

titles_top1000_cleaned <- unique(titles_top1000_cleaned)

years_top1000 <- lapply(urls, function(url) {
  page <- read_html(url_top1000, encoding = "UTF-8")
  titles_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Title için CSS seçicisi
  titles <- html_text(titles_nodes)
  return(titles)
})

years_top1000_cleaned <- c()
for (a in years_top1000) {
  x <- grep("^[0-9]+$", a, value = TRUE)
  years_top1000_cleaned <- c(years_top1000_cleaned, x)
}
years_top1000_cleaned <- as.integer(years_top1000_cleaned)

final_top1000 <- data.frame(Title = titles_top1000_cleaned,
                            Year = years_top1000_cleaned)
final_top1000 <- unique(final_top1000)

final_top1000_extended <- merge(final_top1000, final_data, all.x = TRUE)

final_top1000_extended_rated <- final_top1000_extended[order(final_top1000_extended$Rating, decreasing = TRUE),]
#The two lists are not identical, I first checked that if it is related to votes but it is not, which means there may be an algorithm to calculate a score for ranking, or something else.

```
