for (x in all_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
all_titles_cleaned <- c(all_titles_cleaned, a)
}
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
#library(gridExtra)
library(rvest)
# URL'leri içeren vektör
urls <- c("https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-03-11&num_votes=2500,&country_of_origin=TR&count=250" ,
"https://m.imdb.com/search/title/?title_type=feature&release_date=,2010-01-01&num_votes=2500,&country_of_origin=TR&count=250")
# Her URL için HTML içeriğini oku ve bir listeye kaydet
page <- lapply(urls, function(url) {
read_html(url)
})
# Her URL için HTML içeriğini okuyup, title verilerini çekme
titles_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")
titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
titles <- html_text(titles_nodes)
return(titles)
})
# Her URL'den çekilen title'ları birleştir
all_titles <- unlist(titles_list)
all_titles <- all_titles[!grepl("Advanced", all_titles)]
all_titles <- all_titles[!grepl("Recently", all_titles)]
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
#library(gridExtra)
library(rvest)
# URL'leri içeren vektör
urls <- c("https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-03-11&num_votes=2500,&country_of_origin=TR&count=250" ,
"https://m.imdb.com/search/title/?title_type=feature&release_date=,2010-01-01&num_votes=2500,&country_of_origin=TR&count=250")
# Her URL için HTML içeriğini oku ve bir listeye kaydet
page <- lapply(urls, function(url) {
read_html(url)
})
# Her URL için HTML içeriğini okuyup, title verilerini çekme
titles_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")
titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
titles <- html_text(titles_nodes)
return(titles)
})
# Her URL'den çekilen title'ları birleştir
all_titles <- unlist(titles_list)
all_titles <- all_titles[!grepl("Advanced", all_titles)]
all_titles <- all_titles[!grepl("Recently", all_titles)]
all_titles_cleaned <- c()
for (x in all_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
all_titles_cleaned <- c(all_titles_cleaned, a)
}
all_titles_cleaned
years_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
years_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Year için CSS seçicisi
years <- html_text(years_nodes)
return(years)
})
# Her URL'den çekilen year'ları birleştir
all_years <- unlist(years_list)
years_cleaned <- c()
for (a in title_metadata_list) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- c()
for (a in all_years) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned
years_cleaned <- as.integer(years_cleaned)
durations_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
durations_nodes <- html_nodes(page, '[class$="-child(2)"]')  # Duration için CSS seçicisi
durations <- html_text(durations_nodes)
return(durations)
})
all_durations <- unlist(durations_list)
durations_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
durations_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Duration için CSS seçicisi
durations <- html_text(durations_nodes)
return(durations)
})
durations_cleaned <- c()
for (a in duration_list) {
x <- grep("[hm]", a, value = TRUE)
durations_cleaned <- c(durations_cleaned, x)
}
durations_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
durations_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Duration için CSS seçicisi
durations <- html_text(durations_nodes)
return(durations)
})
durations_cleaned <- c()
for (a in durations_list) {
x <- grep("[hm]", a, value = TRUE)
durations_cleaned <- c(durations_cleaned, x)
}
durations_cleaned
durations_in_minutes <- data.frame(durations_cleaned) %>%
# Saat ve dakika bilgilerini ayırma
mutate(hours = str_extract(durations_cleaned, "\\d+(?=h)"),
minutes = str_extract(durations_cleaned, "\\d+(?=m)")) %>%
# Eksik saat ve dakika değerlerini 0 ile doldurma
mutate(hours = replace_na(hours, 0),
minutes = replace_na(minutes, 0)) %>%
# Saat bilgisini dakikaya çevirme ve dakika bilgisiyle toplama
mutate(total_minutes = as.numeric(hours) * 60 + as.numeric(minutes)) %>%
# Sonuçları tam sayıya dönüştürme
mutate(total_minutes = as.integer(total_minutes)) %>%
# Sadece sonuçları içeren bir sütun seçme
select(total_minutes)
library(dplyr)
durations_in_minutes <- data.frame(durations_cleaned) %>%
# Saat ve dakika bilgilerini ayırma
mutate(hours = str_extract(durations_cleaned, "\\d+(?=h)"),
minutes = str_extract(durations_cleaned, "\\d+(?=m)")) %>%
# Eksik saat ve dakika değerlerini 0 ile doldurma
mutate(hours = replace_na(hours, 0),
minutes = replace_na(minutes, 0)) %>%
# Saat bilgisini dakikaya çevirme ve dakika bilgisiyle toplama
mutate(total_minutes = as.numeric(hours) * 60 + as.numeric(minutes)) %>%
# Sonuçları tam sayıya dönüştürme
mutate(total_minutes = as.integer(total_minutes)) %>%
# Sadece sonuçları içeren bir sütun seçme
select(total_minutes)
convert_to_minutes <- function(durations_cleaned) {
# Süreyi 'h' ve 'm'ye göre ayırma
parts <- strsplit(durations_cleaned, "h|m")
# Saat ve dakikayı ayrıştırma
hours <- as.numeric(parts[[1]][1])
minutes <- ifelse(length(parts[[1]]) > 2, as.numeric(parts[[1]][2]), 0)
# Toplam süreyi dakika cinsinden hesaplama
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
# Tüm süreleri dönüştürme
minutes <- sapply(durations, convert_to_minutes)
convert_to_minutes <- function(durations_cleaned) {
# Süreyi 'h' ve 'm'ye göre ayırma
parts <- strsplit(durations_cleaned, "h|m")
# Saat ve dakikayı ayrıştırma
hours <- as.numeric(parts[[1]][1])
minutes <- ifelse(length(parts[[1]]) > 2, as.numeric(parts[[1]][2]), 0)
# Toplam süreyi dakika cinsinden hesaplama
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
# Tüm süreleri dönüştürme
minutes <- sapply(durations_cleaned, convert_to_minutes)
minutes
durations_in_minutes <- data.frame(durations_cleaned) %>%
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
library(dplyr)
library(rvest)
# URL'leri içeren vektör
urls <- c("https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-03-11&num_votes=2500,&country_of_origin=TR&count=250" ,
"https://m.imdb.com/search/title/?title_type=feature&release_date=,2010-01-01&num_votes=2500,&country_of_origin=TR&count=250")
# Her URL için HTML içeriğini oku ve bir listeye kaydet
page <- lapply(urls, function(url) {
read_html(url)
})
# Her URL için HTML içeriğini okuyup, title verilerini çekme
titles_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")
titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
titles <- html_text(titles_nodes)
return(titles)
})
# Her URL'den çekilen title'ları birleştir
all_titles <- unlist(titles_list)
all_titles <- all_titles[!grepl("Advanced", all_titles)]
all_titles <- all_titles[!grepl("Recently", all_titles)]
all_titles_cleaned <- c()
for (x in all_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
all_titles_cleaned <- c(all_titles_cleaned, a)
}
years_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
years_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Year için CSS seçicisi
years <- html_text(years_nodes)
return(years)
})
# Her URL'den çekilen year'ları birleştir
all_years <- unlist(years_list)
years_cleaned <- c()
for (a in all_years) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- as.integer(years_cleaned)
durations_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
durations_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Duration için CSS seçicisi
durations <- html_text(durations_nodes)
return(durations)
})
durations_cleaned <- c()
for (a in durations_list) {
x <- grep("[hm]", a, value = TRUE)
durations_cleaned <- c(durations_cleaned, x)
}
convert_to_minutes <- function(durations_cleaned) {
# Süreleri saat ve dakika olarak ayırma
parts <- strsplit(durations_cleaned, "h|m")[[1]]
# Saat ve dakika değerlerini sayısal değere dönüştürme
hours <- as.numeric(parts[1])
minutes <- as.numeric(parts[2])
# Toplam süreyi dakika cinsinden hesaplama
total_minutes <- (hours * 60) + minutes
return(total_minutes)
}
# Örnek kullanım
minutes <- sapply(durations_cleaned, convert_to_minutes)
print(minutes)
durations_converted <- convert_to_minutes(durations_cleaned)
durations_converted
durations_converted <- sapply(durations_cleaned, convert_to_minutes)
durations_converted
durations_added <- sapply(durations_cleaned, convert_to_minutes)
durations_converted <- durations_added[2,]
durations_converted <- durations_added[,2]
durations_converted <- durations_added[2, ]
durations_added <- mutate(durations_cleaned, convert_to_minutes)
durations_added <- convert_to_minutes(durations_cleaned)
durations_added
durations_added <- convert_to_minutes(c(durations_cleaned))
durations_added
convert_to_minutes <- function(durations_cleaned) {
parts <- strsplit(durations_cleaned, "h|m")[[1]]
hours <- as.numeric(parts[1])
minutes <- as.numeric(parts[2])
return((hours * 60) + minutes)
}
# Veri setindeki tüm süreleri dakikaya dönüştürme ve bir vektör olarak saklama
minutes_only <- sapply(durations_cleaned, convert_to_minutes)
# Dakika olarak dönüştürülmüş süreleri gösterme
print(minutes_only)
print(minutes_only[2, ])
convert_to_minutes <- function(durations_cleaned) {
hours <- as.numeric(str_extract(durations_cleaned, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(durations_cleaned, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
durations_converted
durations_cleaned <- c()
for (a in durations_list) {
x <- grep("[hm]", a, value = TRUE)
durations_cleaned <- c(durations_cleaned, x)
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
}
convert_to_minutes <- function(durations_cleaned) {
hours <- as.numeric(str_extract(durations_cleaned, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(durations_cleaned, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
}
library(stringr)
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
library(dplyr)
library(rvest)
convert_to_minutes <- function(durations_cleaned) {
hours <- as.numeric(str_extract(durations_cleaned, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(durations_cleaned, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
}
ratings_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
ratings_nodes <- html_nodes(page, '.ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating')  # Ratings için CSS seçicisi
ratings <- html_text(ratings_nodes)
return(ratings)
})
# Her URL'den çekilen ratings'ları birleştir
all_ratings <- unlist(ratings_list)
all_ratings
# Her URL'den çekilen ratings'ları birleştir
all_ratings <- unlist(ratings_list)
ratings_cleaned <- c()
for (x in all_ratings) {
rating_elements <- sub("^([0-9]\\.[0-9]).*$", "\\1", x)
ratings_cleaned <- c(ratings_cleaned, rating_elements)
}
ratings_cleaned
ratings_integer <- as.numeric(ratings_cleaned)
ratings_integer
ratings_cleaned_integer <- as.numeric(ratings_cleaned)
ratings_cleaned_integer
votes_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  # Votes için CSS seçicisi
votes <- html_text(votes_nodes)
return(votes)
votes
votes_list
all_votes <- unlist(votes_list)
all_votes
votes_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  # Votes için CSS seçicisi
votes <- html_text(votes_nodes)
return(votes)
votes_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  # Votes için CSS seçicisi
votes <- html_text(votes_nodes)
return(votes)
})
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
library(dplyr)
library(rvest)
votes_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  # Votes için CSS seçicisi
votes <- html_text(votes_nodes)
return(votes)
})
all_votes <- unlist(votes_list)
all_votes
votes_cleaned <- as.numeric(sapply(vote_list, function(x) {
numeric_value <- gsub("Votes|,", "", x)
}))
votes_cleaned <- as.numeric(sapply(all_votes, function(x) {
numeric_value <- gsub("Votes|,", "", x)
}))
head(votes_cleaned)
votes
votes_cleaned
final_data <- data.frame(Title = all_titles_cleaned,
Year = years_cleaned,
Duration = durations_converted,
Rating = ratings_cleaned_integer,
Vote = votes_cleaned)
final_data
summary(final_data)
Final_data_rated <- final_data[order(final_data$Rating, TRUE)]
Final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE)]
final_data[order(final_data$Rating, decreasing = TRUE)]
library(tidyverse)
library(rvest)
library(stringr)
library(scales)
library(dplyr)
library(rvest)
# URL'leri içeren vektör
urls <- c("https://m.imdb.com/search/title/?title_type=feature&release_date=2010-01-01,2023-03-11&num_votes=2500,&country_of_origin=TR&count=250" ,
"https://m.imdb.com/search/title/?title_type=feature&release_date=,2010-01-01&num_votes=2500,&country_of_origin=TR&count=250")
# Her URL için HTML içeriğini oku ve bir listeye kaydet
page <- lapply(urls, function(url) {
read_html(url)
})
# Her URL için HTML içeriğini okuyup, title verilerini çekme
titles_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")
titles_nodes <- html_nodes(page, '.ipc-title__text')  # Title için CSS seçicisi
titles <- html_text(titles_nodes)
return(titles)
})
# Her URL'den çekilen title'ları birleştir
all_titles <- unlist(titles_list)
all_titles <- all_titles[!grepl("Advanced", all_titles)]
all_titles <- all_titles[!grepl("Recently", all_titles)]
all_titles_cleaned <- c()
for (x in all_titles) {
a <- gsub("^[0-9]+\\.\\s*", "", x)
all_titles_cleaned <- c(all_titles_cleaned, a)
}
years_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
years_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Year için CSS seçicisi
years <- html_text(years_nodes)
return(years)
})
# Her URL'den çekilen year'ları birleştir
all_years <- unlist(years_list)
years_cleaned <- c()
for (a in all_years) {
x <- grep("^[0-9]+$", a, value = TRUE)
years_cleaned <- c(years_cleaned, x)
}
years_cleaned <- as.integer(years_cleaned)
durations_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
durations_nodes <- html_nodes(page, '.sc-43986a27-8.jHYIIK.dli-title-metadata-item')  # Duration için CSS seçicisi
durations <- html_text(durations_nodes)
return(durations)
})
durations_cleaned <- c()
for (a in durations_list) {
x <- grep("[hm]", a, value = TRUE)
durations_cleaned <- c(durations_cleaned, x)
}
convert_to_minutes <- function(durations_cleaned) {
hours <- as.numeric(str_extract(durations_cleaned, "\\d+(?=h)"))
minutes <- as.numeric(str_extract(durations_cleaned, "\\d+(?=m)"))
if (is.na(hours)) { hours <- 0 }
if (is.na(minutes)) { minutes <- 0 }
total_minutes <- hours * 60 + minutes
return(total_minutes)
}
durations_converted <- c()
for (a in durations_cleaned){
x <- convert_to_minutes(a)
durations_converted <- c(durations_converted, x)
}
ratings_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
ratings_nodes <- html_nodes(page, '.ipc-rating-star.ipc-rating-star--base.ipc-rating-star--imdb.ratingGroup--imdb-rating')  # Ratings için CSS seçicisi
ratings <- html_text(ratings_nodes)
return(ratings)
})
# Her URL'den çekilen ratings'ları birleştir
all_ratings <- unlist(ratings_list)
ratings_cleaned <- c()
for (x in all_ratings) {
rating_elements <- sub("^([0-9]\\.[0-9]).*$", "\\1", x)
ratings_cleaned <- c(ratings_cleaned, rating_elements)
}
ratings_cleaned_integer <- as.numeric(ratings_cleaned)
votes_list <- lapply(urls, function(url) {
page <- read_html(url, encoding = "UTF-8")  # UTF-8 kodlaması kullanılıyor
votes_nodes <- html_nodes(page, '.sc-53c98e73-0.kRnqtn')  # Votes için CSS seçicisi
votes <- html_text(votes_nodes)
return(votes)
})
all_votes <- unlist(votes_list)
votes_cleaned <- as.numeric(sapply(all_votes, function(x) {
numeric_value <- gsub("Votes|,", "", x)
}))
final_data <- data.frame(Title = all_titles_cleaned,
Year = years_cleaned,
Duration = durations_converted,
Rating = ratings_cleaned_integer,
Vote = votes_cleaned)
Final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE)]
Final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE)]
final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE)]
final_data_rated <- final_data[order(final_data$Rating, decreasing = TRUE),]
best_five <- head(final_data_rated)
worst_five <- tail(final_data_rated)
best_five
worst_five
cem_yilmaz_classics <- final_data %>% filter(Title == "G.O.R.A.")
cem_yilmaz_classics
cem_yilmaz_classics <- final_data %>% filter(Title == c("G.O.R.A.","Borç Harç"))
cem_yilmaz_classics
cem_yilmaz_classics
View(cem_yilmaz_classics)
View(final_data)
View(final_data)
View(final_data)
final_data
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
View(cem_yilmaz_classics)
best_five
